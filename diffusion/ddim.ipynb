{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2d00f0-fbff-4fb6-a57e-d4e7258d9f7d",
   "metadata": {},
   "source": [
    "# SIGE Benchmark on DDIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2413ae-2341-4b34-af75-0aeeeb458375",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "### Installation (This may take several minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ef201-c346-46f9-ac0e-d76e4356edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install git+https://github.com/lmxyy/sige.git\n",
    "!pip install torchprofile wget tqdm ipyplot pyyaml easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331f971-465c-4395-9232-2c5ab77ba981",
   "metadata": {},
   "source": [
    "### Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417bc8f-0f73-4d07-9d99-f017693aded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/lmxyy/sige.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6abcf-ad52-45f2-95cb-3c7b6c58b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"sige/diffusion\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ee0ac-14e1-40e4-89ff-809e41c3f677",
   "metadata": {},
   "source": [
    "### Create Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79136b97-9159-48eb-a110-21d2edaa0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "from utils import set_seed\n",
    "\n",
    "with open(\"configs/church_ddim256-original.yml\", \"r\") as f:\n",
    "    config_vanilla = yaml.safe_load(f)\n",
    "config_vanilla = EasyDict(config_vanilla)\n",
    "with open(\"configs/church_ddim256-sige.yml\", \"r\") as f:\n",
    "    config_sige = yaml.safe_load(f)\n",
    "config_sige = EasyDict(config_sige)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "config_vanilla.device = device\n",
    "config_sige.device = device\n",
    "\n",
    "# Build a dummy args\n",
    "args = Namespace()\n",
    "set_seed(0)  # for reproducibility, feel free to change the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13fa9d",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e43020",
   "metadata": {},
   "source": [
    "Define Some helper functions for creating the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from download_helper import get_ckpt_path\n",
    "from models.ddim_arch.unet import UNet\n",
    "from models.ddim_arch.sige_fused_unet import SIGEFusedUNet\n",
    "from models.ema import EMAHelper\n",
    "\n",
    "def build_model(args, config):\n",
    "    network: str = config.model.network\n",
    "    if network == \"ddim.unet\":\n",
    "        Model = UNet\n",
    "    elif network == 'ddim.sige_fused_unet':\n",
    "        Model = SIGEFusedUNet\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown network [%s]!!!\" % network)\n",
    "    model = Model(args, config)\n",
    "    model = model.to(device)\n",
    "\n",
    "    if config.model.ema:\n",
    "        ema_helper = EMAHelper(mu=config.model.ema_rate)\n",
    "        ema_helper.register(model)\n",
    "    else:\n",
    "        ema_helper = None\n",
    "\n",
    "    return model, ema_helper\n",
    "\n",
    "def restore_checkpoint(model: nn.Module, ema_helper: Optional[EMAHelper], path: str):\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "    states = torch.load(path)\n",
    "    model.load_state_dict(states[\"model\"])\n",
    "    if ema_helper is not None:\n",
    "        if \"ema\" not in states:\n",
    "            ema_helper.register(model)\n",
    "        else:\n",
    "            ema_helper.load_state_dict(states[\"ema\"])\n",
    "    return model, ema_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27575180",
   "metadata": {},
   "source": [
    "Build vanilla model. **It may take some time to download the model weights. Sometimes the downloading may get stuck. You could rerun the cell or download the weights manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla DDIM Model\n",
    "vanilla_model, vanilla_ema_helper = build_model(args, config_vanilla)\n",
    "pretrained_path = get_ckpt_path(config_vanilla)\n",
    "restore_checkpoint(vanilla_model, vanilla_ema_helper, pretrained_path)\n",
    "vanilla_model.eval()\n",
    "print('Vanilla model is built successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d8cd2",
   "metadata": {},
   "source": [
    "Build SIGE model. **It may take some time to download the model weights. Sometimes the downloading may get stuck. You could rerun the cell or download the weights manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGE DDIM Model\n",
    "sige_model, sige_ema_helper = build_model(args, config_sige)\n",
    "pretrained_path = get_ckpt_path(config_sige)\n",
    "restore_checkpoint(sige_model, sige_ema_helper, pretrained_path)\n",
    "sige_model.eval()\n",
    "print('SIGE model is built successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4006c19",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "We have prepared two pairs of user edits in [`./assets`](./assets). Here, we use [`./assets/original.png`](./assets/original.png) as the original image and [`./assets/edited.png`](./assets/edited.png) as the edited image. You are free to use any other pairs of data either in our benchmark dataset (see [README.md](./README.md)) or created yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e205e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "original_image_path = './assets/original.png'\n",
    "edited_image_path = './assets/edited.png'\n",
    "\n",
    "original_image = Image.open(original_image_path)\n",
    "edited_image = Image.open(edited_image_path)\n",
    "\n",
    "assert config_vanilla.data.image_size == config_sige.data.image_size\n",
    "image_size = config_vanilla.data.image_size\n",
    "resize = transforms.Resize(image_size)\n",
    "original_image = resize(original_image)\n",
    "edited_image = resize(edited_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd653d5d",
   "metadata": {},
   "source": [
    "Display the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1434e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyplot\n",
    "import numpy as np\n",
    "\n",
    "ipyplot.plot_images(\n",
    "    (np.array(original_image), np.array(edited_image)), \n",
    "    (\"Original\", \"Edited\"),\n",
    "    img_width=image_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc64a4f",
   "metadata": {},
   "source": [
    "Convert the images to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b07db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor = transforms.ToTensor()\n",
    "original_image = toTensor(original_image).unsqueeze(0).to(device)\n",
    "edited_image = toTensor(edited_image).unsqueeze(0).to(device)\n",
    "\n",
    "# Rescale the tensors to [-1, 1]\n",
    "original_image = 2 * original_image - 1\n",
    "edited_image = 2 * edited_image - 1\n",
    "\n",
    "e = torch.randn_like(original_image)\n",
    "x0s = torch.cat([original_image, edited_image], dim=0)\n",
    "es = torch.cat([e, e], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e0485",
   "metadata": {},
   "source": [
    "Compute the difference masks. `sige` has some helper functions for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sige.utils import compute_difference_mask, dilate_mask, downsample_mask\n",
    "\n",
    "assert config_vanilla.sampling.eps == config_sige.sampling.eps\n",
    "assert config_vanilla.sampling.mask_dilate_radius == config_sige.sampling.mask_dilate_radius\n",
    "\n",
    "eps = config_vanilla.sampling.eps\n",
    "mask_dilate_radius = config_vanilla.sampling.mask_dilate_radius\n",
    "\n",
    "difference_mask = compute_difference_mask(original_image, edited_image, eps=eps)\n",
    "difference_mask = dilate_mask(difference_mask, mask_dilate_radius)\n",
    "\n",
    "# Downsample the mask to different resolutions\n",
    "masks = downsample_mask(difference_mask, image_size // (2 ** (len(config_vanilla.model.ch_mult) - 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840c898",
   "metadata": {},
   "source": [
    "Visualize the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_image(mask: torch.Tensor):\n",
    "    mask_numpy = mask.cpu().numpy()\n",
    "    image = Image.fromarray(mask_numpy)\n",
    "    image = image.resize((image_size, image_size))\n",
    "    return image\n",
    "\n",
    "mask_image = mask_to_image(difference_mask)\n",
    "message = \"Sparsity: %.2f%%\" % (100 * difference_mask.sum() / difference_mask.numel())\n",
    "ipyplot.plot_images((np.array(mask_image),), (\"Difference Mask\",), (message,), img_width=image_size)\n",
    "\n",
    "print(\"Downsampled Masks\")\n",
    "arrays, labels, messages = [], [], []\n",
    "for i, (k, v) in enumerate(masks.items()):\n",
    "    image = mask_to_image(v)\n",
    "    arrays.append(np.array(image))\n",
    "    labels.append(\"Resolution: %dx%d\" % (k[0], k[1]))\n",
    "    messages.append(\"Sparsity: %.2f%%\" % (100 * v.sum() / v.numel()))\n",
    "ipyplot.plot_images(arrays, labels, messages, img_width=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faffc7a",
   "metadata": {},
   "source": [
    "## Test Models\n",
    "### Quality Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c377c",
   "metadata": {},
   "source": [
    "Define the DDIM sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94550f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplers.ddim_sampler import DDIMSampler as Sampler\n",
    "\n",
    "# The same, the sampler should be the same for both the original model and SIGE model.\n",
    "sampler = Sampler(args, config_vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ae532",
   "metadata": {},
   "source": [
    "Get some diffusion variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeebac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_sequence(config, noise_level=None):\n",
    "    if noise_level is None:\n",
    "        noise_level = config.total_steps\n",
    "\n",
    "    skip_type = config.sampling.skip_type\n",
    "    timesteps = config.sampling.sample_steps\n",
    "\n",
    "    if skip_type == \"uniform\":\n",
    "        skip = noise_level // timesteps\n",
    "        seq = range(0, noise_level, skip)\n",
    "    elif skip_type == \"quad\":\n",
    "        seq = np.linspace(0, np.sqrt(noise_level * 0.8), timesteps - 1) ** 2\n",
    "        seq = [int(s) for s in list(seq)]\n",
    "        seq.append(noise_level)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown skip type [%s]!!!\" % skip_type)\n",
    "    return seq\n",
    "\n",
    "# The sampling sequence should be the same for both the original model and SIGE model.\n",
    "seq = get_sampling_sequence(config_vanilla, noise_level=config_vanilla.sampling.noise_level)\n",
    "ts = torch.full((x0s.size(0),), seq[-1], device=x0s.device, dtype=torch.long)  # The starting timestep\n",
    "xts = sampler.get_xt_from_x0(x0s, ts, es)  # Preturb the image with the corresponding noise level\n",
    "gt_x0, gt_e = x0s[:1], es[:1]  # Used for the mask trick in SDEdit to keep the unedited regions unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799a350",
   "metadata": {},
   "source": [
    "Start denoising.\n",
    "* Denoising with the vanilla model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79342dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vanilla_generate_x0s = sampler.denoising_steps(\n",
    "        xts[1:], vanilla_model, seq, \n",
    "        gt_x0=gt_x0, gt_e=gt_e, \n",
    "        difference_mask=difference_mask\n",
    "    )\n",
    "    vanilla_result = (vanilla_generate_x0s[0] + 1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c96bb",
   "metadata": {},
   "source": [
    "* Denoising with the SIGE model. Currently, `sige` only support caching the model for a single step. Therefore, we run a simple simulation to get the results: For every denoising step, we first denoise the noisy original image (`xts[:1]`) to cache the activations and run the actual sparse inference on `xts[1:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Need a pre-run to determine the data shape\n",
    "    sige_model.set_mode(\"full\")\n",
    "    sige_model(original_image, torch.zeros(1, device=device, dtype=torch.float32))\n",
    "\n",
    "    # Set the difference masks for the sparse inference. \n",
    "    # It will automatically reduce the masks to active indices.\n",
    "    sige_model.set_masks(masks)\n",
    "    \n",
    "    sige_generate_x0s = sampler.denoising_steps(\n",
    "        xts, sige_model, seq, \n",
    "        gt_x0=gt_x0, gt_e=gt_e, \n",
    "        difference_mask=difference_mask\n",
    "    )\n",
    "    sige_result = (sige_generate_x0s[1] + 1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2bb64",
   "metadata": {},
   "source": [
    "Visualize these two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_result = vanilla_result.clip(0, 1).permute(1, 2, 0).cpu().numpy()\n",
    "vanilla_result = (vanilla_result * 255).astype(np.uint8)\n",
    "vanilla_image = Image.fromarray(vanilla_result)\n",
    "\n",
    "sige_result = sige_result.clip(0, 1).permute(1, 2, 0).cpu().numpy()\n",
    "sige_result = (sige_result * 255).astype(np.uint8)\n",
    "sige_image = Image.fromarray(sige_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfe657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyplot\n",
    "import numpy as np\n",
    "\n",
    "ipyplot.plot_images((np.array(vanilla_image), np.array(sige_image)), (\"Vanilla\", \"SIGE\"), img_width=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af169e",
   "metadata": {},
   "source": [
    "These two images should be very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017e817",
   "metadata": {},
   "source": [
    "### Efficiency Results\n",
    "First, let's profile the MACs of these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16233aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchprofile import profile_macs\n",
    "\n",
    "# Create some dummy inputs\n",
    "dummy_inputs = (x0s[:1], ts[:1])\n",
    "\n",
    "with torch.no_grad():\n",
    "    vanilla_macs = profile_macs(vanilla_model, dummy_inputs)\n",
    "\n",
    "    # For the SIGE model, we need to first run it in the `full`` mode to cache the results.\n",
    "    sige_model.set_mode(\"full\")\n",
    "    sige_model(*dummy_inputs)\n",
    "\n",
    "    # Check to the `profile` mode to profile MACs. This mode is only for the MACs profiling.\n",
    "    sige_model.set_mode(\"profile\")\n",
    "    sige_macs = profile_macs(sige_model, dummy_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efdc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vanilla MACs: %.3fG' % (vanilla_macs / 1e9))\n",
    "print('SIGE MACs: %.3fG' % (sige_macs / 1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7310306",
   "metadata": {},
   "source": [
    "SIGE model has a $\\sim 3.3\\times$ MACs reduction. Now let's measure the latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Change these numbers if they are too large for you.\n",
    "warmup_times = 100\n",
    "test_times = 100\n",
    "\n",
    "def measure_latency(model: nn.Module):\n",
    "    for i in tqdm(range(warmup_times)):\n",
    "        model(*dummy_inputs)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    for i in tqdm(range(test_times)):\n",
    "        model(*dummy_inputs)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "    cost_time = time.time() - start_time\n",
    "    return cost_time, cost_time / test_times\n",
    "\n",
    "with torch.no_grad():\n",
    "    vanilla_cost, vanilla_avg = measure_latency(vanilla_model)\n",
    "\n",
    "    # As we have already cached some dummy results for the SIGE model, no need to rerun it in the `full` mode.\n",
    "    # Check to the `sparse` mode to test the latency.\n",
    "    sige_model.set_mode(\"sparse\")\n",
    "    sige_cost, sige_avg = measure_latency(sige_model)\n",
    "\n",
    "print('Vanilla: Cost %.2fs Avg %.2fms' % (vanilla_cost, vanilla_avg * 1000))\n",
    "print('SIGE: Cost %.2fs Avg %.2fms' % (sige_cost, sige_avg * 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sige')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a53578490a19b1a10427dd96133b1520f35d2ed5f51c73f25576be6cae6f29b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
